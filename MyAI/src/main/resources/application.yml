spring:
  application:
    name: MyAI
  config:
    import: optional:classpath:.env[.properties]
  data:
    mongodb:
      uri: mongodb://${MONGO_HOST}:27017/ai_test
server:
  port: 8080

langchain4j:
  open-ai:
    chat-model:
#       OPen AI Test
#            base-url: http://langchain4j.dev/demo/openai/v1
#            api-key: demo
#            model-name: gpt-4o-mini
#            log-requests: true
#            log-responses: true
#            timeout: 60s

      # deepseek model
      #       base-url: https://api.deepseek.com
      #       api-key: ${DEEP_SEEK_TOKEN}
      ##       model-name: deepseek-chat
      #       model-name: deepseek-reasoner # R1 推理模型
      #       log-requests: true
      #       log-responses: true
      #       timeout: 60s
      # 接入阿里百炼平台 deepseek
      base-url: https://dashscope.aliyuncs.com/compatible-mode/v1
      api-key: ${ALI_BAILIAN_TOKEN}
      model-name: deepseek-v3
#      log-requests: true

#      log-responses: true
      timeout: 60s
      #温度系数：取值范围通常在 0 到 1 之间。值越高，模型的输出越随机、富有创造性；
      # 值越低，输出越确定、保守。这里设置为 0.9，意味着模型会有一定的随机性，生成的回复可能会比较多样化
      temperature: 0.9
  # 接入本地 ollama deepseek
  ollama:
    chat-model:
      base-url: http://localhost:11434
      model-name: deepseek-r1:1.5b
      log-requests: true
      log-responses: true

  # 接入阿里百炼平台
  community:
    dashscope:
      chat-model:
        api-key: ${ALI_BAILIAN_TOKEN}
        model-name: qwen-max
      streaming-chat-model:
        api-key: ${ALI_BAILIAN_TOKEN}
        model-name: qwen-plus

#logging:
#  level:
#    root: debug


